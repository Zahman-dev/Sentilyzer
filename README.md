# Sentilyzer - Finansal Duygu Analizi ve Geri Test Platformu

## Proje Vizyonu

Finansal metin verilerini, iÅŸlenebilir stratejik iÃ§gÃ¶rÃ¼lere dÃ¶nÃ¼ÅŸtÃ¼ren, Ã¶lÃ§eklenebilir, bakÄ±mÄ± kolay ve geniÅŸletilebilir bir platform yaratmak. Sistem, bir "veri fabrikasÄ±" gibi Ã§alÄ±ÅŸmalÄ±dÄ±r; bir uÃ§tan ham madde (metin) girer, montaj hatlarÄ±ndan (servisler) geÃ§er ve diÄŸer uÃ§tan deÄŸerli bir Ã¼rÃ¼n (analiz/strateji sonucu) Ã§Ä±kar.

## Temel Mimari

Sistem, **Olay GÃ¼dÃ¼mlÃ¼ (Event-Driven)** ve **Servis OdaklÄ± (Service-Oriented)** bir mimariye dayanÄ±r. Servisler birbirlerini doÄŸrudan Ã§aÄŸÄ±rmazlar; bunun yerine veritabanÄ±ndaki durum deÄŸiÅŸikliklerine (olaylara) tepki verirler. Bu, sistemin esnekliÄŸini ve dayanÄ±klÄ±lÄ±ÄŸÄ±nÄ± (resilience) en Ã¼st dÃ¼zeye Ã§Ä±karÄ±r.

## Temel TasarÄ±m KararlarÄ± ve GerekÃ§eleri

Bu proje, sadece belirli teknolojileri kullanmakla kalmaz, aynÄ± zamanda bu seÃ§imlerin arkasÄ±ndaki felsefeyi de benimser. Her bir teknoloji ve mimari desen, platformun uzun vadeli hedefleri olan **Ã¶lÃ§eklenebilirlik**, **bakÄ±m kolaylÄ±ÄŸÄ±** ve **dayanÄ±klÄ±lÄ±ÄŸÄ± (resilience)** desteklemek iÃ§in dikkatle seÃ§ilmiÅŸtir.

*   **Neden Servis OdaklÄ± Mimari (Service-Oriented Architecture)?**
    *   **Hata Ä°zolasyonu:** Bir servis (Ã¶rn: `sentiment_processor`) Ã§Ã¶kse bile, sistemin geri kalanÄ± (Ã¶rn: `data_ingestor`, `signals_api`) Ã§alÄ±ÅŸmaya devam eder.
    *   **BaÄŸÄ±msÄ±z Ã–lÃ§eklendirme:** EÄŸer duygu analizi iÅŸlemi yavaÅŸlarsa, sadece o iÅŸi yapan `celery_worker` sayÄ±sÄ±nÄ± artÄ±rÄ±rÄ±z. TÃ¼m platformu yatayda bÃ¼yÃ¼tmek zorunda kalmayÄ±z.
    *   **Teknoloji Ã–zgÃ¼rlÃ¼ÄŸÃ¼:** Gelecekte duygu analizi modelini Python yerine Rust ile yazmak istersek, bunu diÄŸer servisleri etkilemeden yapabiliriz.

*   **Neden VeritabanÄ± Ãœzerinden Olay GÃ¼dÃ¼mlÃ¼ Ä°letiÅŸim?**
    *   **DayanÄ±klÄ±lÄ±k:** Veri toplayÄ±cÄ± servis, veriyi veritabanÄ±na yazdÄ±ÄŸÄ± an gÃ¶revini tamamlamÄ±ÅŸ sayÄ±lÄ±r. Analiz servisi o an Ã§alÄ±ÅŸmÄ±yor olsa bile veri kaybolmaz; servis ayaÄŸa kalktÄ±ÄŸÄ±nda kaldÄ±ÄŸÄ± yerden devam eder.
    *   **Basitlik ve AyrÄ±klÄ±k (Decoupling):** Servislerin birbirlerinin aÄŸ adresini veya API'Ä±nÄ± bilmesi gerekmez. Tek iletiÅŸim noktasÄ± veritabanÄ±dÄ±r. Bu, sistemi Ã§ok daha basit ve yÃ¶netilebilir kÄ±lar.

*   **Neden Celery & Redis ile Asenkron GÃ¶rev YÃ¶netimi?**
    *   **API'Ä±n TÄ±kanmasÄ±nÄ± Ã–nleme:** Bir kullanÄ±cÄ±nÄ±n API isteÄŸiyle 10 dakika sÃ¼recek bir rapor oluÅŸturmak, kullanÄ±cÄ±yÄ± bekletir ve sistemi yorar. Celery ile bu iÅŸi anÄ±nda arka plana atÄ±p kullanÄ±cÄ±ya "iÅŸleminiz alÄ±ndÄ±, tamamlanÄ±nca haber vereceÄŸiz" yanÄ±tÄ± dÃ¶nebiliriz.
    *   **Ã–lÃ§eklenebilir Ä°ÅŸ YÃ¼kÃ¼:** GÃ¼nde 100 haber iÅŸlerken 1 `worker` yeterliyken, 1 milyon haber iÅŸlerken `worker` sayÄ±sÄ±nÄ± 50'ye Ã§Ä±kararak aynÄ± hÄ±zda Ã§alÄ±ÅŸmaya devam edebiliriz. Bu esneklik, `APScheduler` gibi servis-iÃ§i bir kÃ¼tÃ¼phane ile mÃ¼mkÃ¼n deÄŸildir.
    *   **GÃ¼venilir Zamanlama:** Periyodik veri toplama gÃ¶revleri, uygulama kodundan baÄŸÄ±msÄ±z, merkezi bir `Celery Beat` servisi tarafÄ±ndan yÃ¶netilir. Bu, zamanlamanÄ±n daha gÃ¼venilir ve yÃ¶netilebilir olmasÄ±nÄ± saÄŸlar.

*   **Neden Alembic ile VeritabanÄ± Versiyonlama?**
    *   **"Kod Olarak Åema" (Schema as Code):** VeritabanÄ± ÅŸemasÄ±nÄ± (tablolar, sÃ¼tunlar) kod gibi Git ile versiyonlamamÄ±zÄ± saÄŸlar.
    *   **TutarlÄ±lÄ±k ve GÃ¼venlik:** Her geliÅŸtiricinin bilgisayarÄ±nda ve production ortamÄ±nda aynÄ± veritabanÄ± ÅŸemasÄ±nÄ±n olmasÄ±nÄ± garanti eder. Manuel, hataya aÃ§Ä±k `ALTER TABLE...` komutlarÄ±nÄ± Ã§alÄ±ÅŸtÄ±rma riskini ortadan kaldÄ±rÄ±r.

*   **Neden Her Åey iÃ§in Docker?**
    *   **"Benim Makinemde Ã‡alÄ±ÅŸÄ±yordu" Sorununu Ã‡Ã¶zmek:** Bir geliÅŸtiricinin makinesinde Ã§alÄ±ÅŸan kodun, baÅŸka bir geliÅŸtiricinin makinesinde veya sunucuda da birebir aynÄ± ÅŸekilde Ã§alÄ±ÅŸacaÄŸÄ±nÄ± garanti eder.
    *   **Ä°zolasyon ve Kolay Kurulum:** Projenin tÃ¼m baÄŸÄ±mlÄ±lÄ±klarÄ± (PostgreSQL, Redis, Python kÃ¼tÃ¼phaneleri) konteynerler iÃ§inde izole edilir. Yeni bir geliÅŸtirici, sadece `docker-compose up` komutuyla tÃ¼m platformu 5 dakika iÃ§inde Ã§alÄ±ÅŸÄ±r hale getirebilir.

```
+---------------------------+
|      DIÅ DÃœNYA (SOURCES)  |
| - Reuters, Bloomberg (RSS)|
| - Twitter API             |
| - SEC Filings (EDGAR)     |
+-------------|-------------+
              |
              â–¼ (1. Veri AlÄ±mÄ±)
+---------------------------+
|    SERVICE 1:             |
|    DATA INGESTOR          |  <<-- (Periyodik olarak tetiklenir: CRON/Scheduler)
|---------------------------|
| Sorumluluk: Veriyi ham     |
| ve deÄŸiÅŸmemiÅŸ olarak     |
| standart bir formatta     |
| sisteme almak.            |
|                           |
| Ã‡Ä±ktÄ±: "raw_articles"     |
| tablosuna yeni kayÄ±t.     |
+-------------|-------------+
              |
              â–¼ (2. OLAY: Yeni Ham Veri Eklendi)
+---------------------------+
|    VERÄ°TABANI (PostgreSQL)|
|      - TEK GERÃ‡EK KAYNAÄI - |
+---------------------------+
| - raw_articles            |
| - sentiment_scores        |
| - backtest_results        |
| - (Gelecekte) price_data  |
+-------------|-------------+
              â–²
              | (3. OLAY: Yeni Ham Veri Bekleniyor)
              |
+-------------|-------------+
|    SERVICE 2:             |
|    SENTIMENT PROCESSOR    | <<-- (SÃ¼rekli veritabanÄ±nÄ± dinler: Polling)
|---------------------------|
| Sorumluluk: Ham metni      |
| alÄ±p, zenginleÅŸtirmek     |
| (duygu analizi).          |
|                           |
| Ã‡Ä±ktÄ±: "sentiment_scores" |
| tablosuna yeni kayÄ±t.     |
+-------------|-------------+
              â–²
              | (4. OLAY: Analiz Sonucu Bekleniyor)
              |
+-------------|-------------+
|    SERVICE 3:             |
|    SIGNALS API            | <<-- (KullanÄ±cÄ± tarafÄ±ndan tetiklenir: HTTP Request)
| (MVP'de "Duygu Veri SaÄŸlayÄ±cÄ±") |
|---------------------------|
| Sorumluluk: Analiz edilmiÅŸ|
| duygu skorlarÄ±nÄ± ve ilgili|
| verileri, isteÄŸe baÄŸlÄ±   |
| olarak sunmak.            |
|                           |
| Ã‡Ä±ktÄ±: JSON response.     |
+-------------|-------------+
              |
              â–¼ (5. API Ã‡aÄŸrÄ±sÄ±)
+---------------------------+
|    SERVICE 4:             |
|    DASHBOARD              |
|---------------------------|
| Sorumluluk: Ä°nsan-bilgisayar|
| etkileÅŸimini saÄŸlamak.    |
|                           |
| Ã‡Ä±ktÄ±: GÃ¶rsel arayÃ¼z.      |
+-------------|-------------+
              |
              â–¼
+---------------------------+
|        KULLANICI          |
+---------------------------+
```

### Problem
Docker containers often face Python import path issues when sharing modules between microservices, especially in development environments where linters show import errors.

### Solution
We implement industry best practices for Docker Python module management:

#### 1. Multi-Stage Docker Builds
```dockerfile
FROM python:3.10.17-slim as base
ENV PYTHONPATH=/app

FROM base as dependencies
# Install dependencies first for better caching

FROM dependencies as application
# Copy modules with proper structure
COPY services/common/app /app/common
COPY services/service_name/app /app/service_name
```

#### 2. Proper Python Package Structure
```
/app/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ common/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ db/
â”‚   â””â”€â”€ schemas/
â””â”€â”€ service_name/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ main.py
```

#### 3. Import Strategy
```python
# Production Docker container path
from common.db.session import create_db_session
from common.db.models import RawArticle
```

#### 4. Development Environment Configuration
VS Code settings in `.vscode/settings.json`:
```json
{
    "python.analysis.extraPaths": [
        "./services/common/app",
        "./services/sentiment_processor/app"
    ],
    "python.analysis.diagnosticSeverityOverrides": {
        "reportMissingImports": "none"
    }
}
```

## Development Setup

### Prerequisites
- Docker and Docker Compose
- VS Code (recommended) with Python extension
- Minimum 4GB RAM for Docker
- Stable internet connection for ML package downloads

### Quick Start

#### Option 1: Using Optimized Build Script (Recommended)
```bash
# Build all services with timeout optimization
./scripts/build_with_retry.sh

# Or build specific service
./scripts/build_with_retry.sh -s sentiment-processor

# Start services
docker-compose up
```

#### Option 2: Standard Docker Compose
```bash
# Build and start services
docker-compose up --build
```

#### Option 3: Manual Build with Optimization
```bash
# Build with timeout settings
DOCKER_BUILDKIT=1 docker-compose build --no-cache --pull
docker-compose up
```

### ğŸš¨ Docker Timeout Issues?
If you encounter timeout errors during build, see [DOCKER_TIMEOUT_SOLUTIONS.md](./DOCKER_TIMEOUT_SOLUTIONS.md) for comprehensive solutions.

### Access Points
- Dashboard: `http://localhost:8501`
- API endpoints: `http://localhost:8888`

### Development Environment
For development with proper import resolution:

1. Open the project in VS Code
2. The `.vscode/settings.json` is pre-configured for Docker development
3. Linter errors for Docker-specific imports are suppressed in development
4. All imports work correctly in production containers

### Container Structure Benefits
- **Isolation**: Each service runs in its own container
- **Scalability**: Services can be scaled independently
- **Consistency**: Same environment in development and production
- **Performance**: Multi-stage builds optimize image size and build time

## Services

### Sentiment Processor
Advanced sentiment analysis using FinBERT model with batch processing capabilities.

**Features:**
- FinBERT model for financial text analysis
- Batch processing for high throughput
- Celery-based asynchronous processing
- Fallback keyword-based analysis

### Data Ingestor
Automated data collection from financial news sources.

**Features:**
- RSS feed processing
- Scheduled data collection
- Duplicate detection
- Error handling and recovery

### Signals API
RESTful API for accessing sentiment data and analytics.

**Endpoints:**
- `/api/v1/sentiment/latest` - Latest sentiment scores
- `/api/v1/sentiment/history` - Historical data
- `/api/v1/analytics/summary` - Aggregated analytics

## Deployment

### Production Deployment
1. Set environment variables in `docker-compose.prod.yml`
2. Deploy using:
   ```bash
   docker-compose -f docker-compose.prod.yml up -d
   ```

### Environment Variables
- `DATABASE_URL`: PostgreSQL connection string
- `REDIS_URL`: Redis connection string
- `API_SECRET_KEY`: API authentication key
- `LOG_LEVEL`: Logging level (INFO, DEBUG, ERROR)

## Monitoring and Logging

All services use structured JSON logging for easy parsing and monitoring. Logs are available through Docker Compose:

```bash
docker-compose logs -f service_name
```

## Contributing

1. Follow the established Docker Python import patterns
2. Add new services using the multi-stage Dockerfile template
3. Update VS Code settings for new service paths
4. Ensure all services follow the common package structure

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Support

For issues related to Docker Python imports or development environment setup, please check the troubleshooting section in the documentation.
